---
title: Creare un subgraph
---

Un subgraph estrae i dati da una blockchain, li elabora e li memorizza in modo che possano essere facilmente interrogati tramite GraphQL.

![Defining a Subgraph](/img/defining-a-subgraph.png)

La definizione del subgraph consiste in alcuni file:

- `subgraph.yaml`: un file YAML contenente il manifesto del subgraph

- `schema.graphql`: uno schema GraphQL che definisce quali dati sono memorizzati per il subgraph e come interrogarli via GraphQL

- `AssemblyScript Mappings`: [AssemblyScript](https://github.com/AssemblyScript/assemblyscript) codice che traduce i dati dell'evento nelle entità definite nello schema (ad esempio `mapping.ts` in questo tutorial)

> Per poter utilizzare il proprio subgraph sulla rete decentralizzata di The Graph, è necessario [creare una chiave API](/deploying/subgraph-studio-faqs/#2-how-do-i-create-an-api-key). Si consiglia di [aggiungere il segnale](/network/curating/#how-to-signal) al subgraph con almeno [10,000 GRT](/network-transition-faq/#how-can-i-ensure-that-my-subgraph-will-be-picked-up-by-indexer-on-the-graph-network).

Prima di entrare nel dettaglio dei contenuti del file manifest, è necessario installare la [Graph CLI](https://github.com/graphprotocol/graph-cli), che servirà per costruire e distribuire un subgraph.

## Installare the Graph CLI

The Graph CLI è scritta in JavaScript e per utilizzarla è necessario installare `yarn` oppure `npm`; in quanto segue si presume che si disponga di yarn.

Una volta che si dispone di `yarn`, installare the Graph CLI eseguendo

**Installare con yarn:**

```bash
yarn global add @graphprotocol/graph-cli
```

**Installare con npm:**

```bash
npm install -g @graphprotocol/graph-cli
```

Una volta installato, il comando `graph init` può essere usato per impostare un nuovo progetto di subgraph, sia da un contratto esistente che da un subgraph di esempio. Questo comando può essere usato per creare un subgraph nel Subgraph Studio passando `graph init --product subgraph-studio`. Se si dispone già di uno smart contract distribuito sulla rete preferita, l'avvio di un nuovo subgraph da quel contratto può essere un buon modo per iniziare.

## Da un contratto esistente

Il comando seguente crea un subgraph che indicizza tutti gli eventi di un contratto esistente. Tenta di recuperare l'ABI del contratto da Etherscan e torna a richiedere il percorso di un file locale. Se manca uno qualsiasi degli argomenti opzionali, il comando viene eseguito attraverso un modulo interattivo.

```sh
graph init \
  --product subgraph-studio
  --from-contract <CONTRACT_ADDRESS> \
  [--network <ETHEREUM_NETWORK>] \
  [--abi <FILE>] \
  <SUBGRAPH_SLUG> [<DIRECTORY>]
```

Il `<SUBGRAPH_SLUG>` è l'ID del subgraph in Subgraph Studio, che si trova nella pagina dei dettagli del subgraph.

## Da un subgraph di esempio

La seconda modalità supportata da `graph init` è la creazione di un nuovo progetto a partire da un subgraph di esempio. Il comando seguente esegue questa operazione:

```sh
graph init --studio <SUBGRAPH_SLUG>
```

Il subgraph di esempio è basato sul contratto Gravity di Dani Grant, che gestisce gli avatar degli utenti ed emette gli eventi `NewGravatar` oppure `UpdateGravatar` ogni volta che gli avatar vengono creati o aggiornati. Il subgraph gestisce questi eventi scrivendo `Gravatar` entities nel Graph Node store e assicurandosi che questi vengano aggiornati in base agli eventi. Le sezioni seguenti analizzeranno i file che compongono il manifesto del subgraph per questo esempio.

## Aggiungere nuove data sources a un subgraph esistente

Dalla `v0.31.0` il `graph-cli` supporta l'aggiunta di nuove sorgenti di dati a un subgraph esistente tramite il comando `graph add`.

```sh
graph add <address> [<subgraph-manifest default: "./subgraph.yaml">]

Opzioni:

      --abi <path>              Percorso dell'ABI del contratto (predefinito: download from Etherscan)
      --contract-name           Nome del contratto (predefinito: Contract)
      --merge-entities          Se unire entità con lo stesso nome (predefinito: false)
      --network-file <path>     Percorso del file di configurazione della rete (predefinito: "./networks.json")
```

Il comando `add` recupera l'ABI da Etherscan (a meno che non sia specificato un percorso ABI con l'opzione `--abi`) e crea una nuova `dataSource` nello stesso modo in cui il comando `graph init` crea una `dataSource` `-from-contract`, aggiornando di conseguenza lo schema e le mappature.

L'opzione `--merge-entities` identifica il modo in cui lo sviluppatore desidera gestire i conflitti tra i nomi di `entità` e `evento`:

- If `true`: il nuovo `dataSource` dovrebbe utilizzare gli `eventHandler` & `entità` esistenti.
- If `false`: una nuova entità & il gestore dell'evento deve essere creato con `${dataSourceName}{EventName}`.

Il contratto `address` sarà scritto in `networks.json` per la rete rilevante.

> **Nota:** Quando si utilizza il cli interattivo, dopo aver eseguito con successo `graph init`, verrà richiesto di aggiungere un nuovo `dataSource`.

## Manifesto di Subgraph

Il manifesto del subgraph `subgraph.yaml` definisce gli smart contract che il subgraph indicizza, a quali eventi di questi contratti prestare attenzione e come mappare i dati degli eventi alle entità che Graph Node memorizza e permette di effettuare query. Le specifiche complete dei manifesti dei subgraph sono disponibili [qui](https://github.com/graphprotocol/graph-node/blob/master/docs/subgraph-manifest.md).

Per il subgraph di esempio, `subgraph.yaml` è:

```yaml
specVersion: 0.0.4
description: Gravatar for Ethereum
repository: https://github.com/graphprotocol/graph-tooling
schema:
  file: ./schema.graphql
dataSources:
  - kind: ethereum/contract
    name: Gravity
    network: mainnet
    source:
      address: '0x2E645469f354BB4F5c8a05B3b30A929361cf77eC'
      abi: Gravity
      startBlock: 6175244
      endBlock: 7175245
    context:
      foo:
        type: Bool
        data: true
      bar:
        type: String
        data: 'bar'
    mapping:
      kind: ethereum/events
      apiVersion: 0.0.6
      language: wasm/assemblyscript
      entities:
        - Gravatar
      abis:
        - name: Gravity
          file: ./abis/Gravity.json
      eventHandlers:
        - event: NewGravatar(uint256,address,string,string)
          handler: handleNewGravatar
        - event: UpdatedGravatar(uint256,address,string,string)
          handler: handleUpdatedGravatar
      callHandlers:
        - function: createGravatar(string,string)
          handler: handleCreateGravatar
      blockHandlers:
        - handler: handleBlock
        - handler: handleBlockWithCall
          filter:
            kind: call
      file: ./src/mapping.ts
```

Le voci importanti da aggiornare per il manifesto sono:

- `description`: una descrizione leggibile dell'aspetto del subgraph. Questa descrizione viene visualizzata da Graph Explorer quando il subgraph viene distribuito al hosted service.

- `repository`: l'URL del repository in cui è possibile trovare il manifesto del subgraph. Questo viene visualizzato anche da Graph Explorer.

- `features`: un elenco di tutti i nomi delle [caratteristiche](#experimental-features) utilizzati.

- `dataSources.source`: l'indirizzo dello smart contract di cui il subgraph è fonte e l'ABI dello smart contract da utilizzare. L'indirizzo è facoltativo; omettendolo, si possono indicizzare gli eventi corrispondenti di tutti i contratti.

- `dataSources.source.startBlock`: il numero opzionale del blocco da cui l'origine dati inizia l'indicizzazione. Nella maggior parte dei casi, si consiglia di utilizzare il blocco in cui è stato creato il contratto.

- `dataSources.source.endBlock`: Il numero opzionale del blocco a cui il data source interrompe l'indicizzazione, incluso quel blocco. È richiesta la versione minima delle specifiche: `0.0.9`.

- `dataSources.context`: coppie del valore chiave che possono essere usate nelle mappature dei subgraph. Supporta vari tipi di dati come `Bool`, `String`, `Int`, `Int8`, `BigDecimal`, `Bytes`, `List`, e `BigInt`. Ogni variabile deve specificare il suo `tipo` e `dati`. Queste variabili di contesto sono poi accessibili nei file di mappatura, offrendo più opzioni configurabili per lo sviluppo del subgraph.

- `dataSources.mapping.entities`: le entità che l'origine dati scrive nell'archivio. Lo schema di ciascuna entità è definito nel file schema.graphql.

- `dataSources.mapping.abis`: uno o più file ABI denominati per il contratto sorgente e per tutti gli altri smart contract con cui si interagisce all'interno delle mappature.

- `dataSources.mapping.eventHandlers`: elenca gli eventi dello smart contract a cui questo subgraph reagisce e i gestori nella mappatura -./src/mapping.ts nell'esempio - che trasformano questi eventi in entità dell'archivio.

- `dataSources.mapping.callHandlers`: elenca le funzioni dello smart contract a cui questo subgraph reagisce e i gestori della mappatura che trasformano gli input e gli output delle chiamate di funzione in entità dell'archivio.

- `dataSources.mapping.blockHandlers`: elenca i blocchi a cui questo subgraph reagisce e i gestori nella mappatura da eseguire quando un blocco viene aggiunto alla chain. Senza un filtro, il gestore del blocco verrà eseguito ogni blocco. È possibile fornire un filtro di chiamata opzionale aggiungendo al gestore un campo `filter` con `kind: call`. Questo eseguirà il gestore solo se il blocco contiene almeno una chiamata al contratto sorgente.

Un singolo subgraph può indicizzare i dati di più smart contract. Aggiungere all'array `dataSources` una voce per ogni contratto da cui devono essere indicizzati i dati.

I trigger per una data source all'interno di un blocco sono ordinati secondo il seguente processo:

1. I trigger di eventi e chiamate sono ordinati prima per indice di transazione all'interno del blocco.
2. I trigger di eventi e chiamate all'interno della stessa transazione sono ordinati secondo una convenzione: prima i trigger di eventi e poi quelli di chiamate, rispettando l'ordine in cui sono definiti nel manifesto.
3. I trigger di blocco vengono eseguiti dopo i trigger di evento e di chiamata, nell'ordine in cui sono definiti nel manifesto.

Queste regole di ordinazione sono soggette a modifiche.

### Ottenere gli ABI

I file ABI devono corrispondere al vostro contratto. Esistono diversi modi per ottenere i file ABI:

- Se state costruendo il vostro progetto, probabilmente avrete accesso alle ABI più recenti.
- Se state costruendo un subgraph per un progetto pubblico, potete scaricare il progetto sul vostro computer e ottenere l'ABI usando [`truffle compile`](https://truffleframework.com/docs/truffle/overview) o usando solc per compilare.
- È possibile trovare l'ABI anche su [Etherscan](https://etherscan.io/), ma non è sempre affidabile, in quanto l'ABI caricato su questo sito potrebbe non essere aggiornato. Assicuratevi di avere l'ABI corretto, altrimenti l'esecuzione del subgraph fallirà.

## Schema GraphQL

Lo schema del subgraph si trova nel file `schema.graphql`. Gli schemi GraphQL sono definiti utilizzando il linguaggio di definizione dell'interfaccia GraphQL. Se non hai mai scritto uno schema GraphQL, si consiglia di dare un'occhiata a questa guida sul sistema di tipi GraphQL. La documentazione di riferimento per gli schemi GraphQL si trova nella sezione [GraphQL API](/querying/graphql-api).

## Definire le entità

Prima di definire le entità, è importante fare un passo indietro e pensare a come i dati sono strutturati e collegati. Tutte le query saranno fatte sul modello di dati definito nello schema del subgraph e sulle entità indicizzate dal subgraph. Per questo motivo, è bene definire lo schema del subgraph in modo che corrisponda alle esigenze della propria applicazione. Può essere utile immaginare le entità come "oggetti contenenti dati", piuttosto che come eventi o funzioni.

Con The Graph, è sufficiente definire i tipi di entità in `schema.graphql` e Graph Node genererà campi di primo livello per interrogare singole istanze e collezioni di quel tipo di entità. Ogni tipo che dovrebbe essere un'entità deve essere annotato con una direttiva `@entity`. Per impostazione predefinita, le entità sono mutabili, il che significa che le mappature possono caricare entità esistenti, modificarle e memorizzare una nuova versione di quell'entità. La mutabilità ha un prezzo e per i tipi di entità per i quali si sa che non saranno mai modificati, ad esempio perché contengono semplicemente dati estratti alla lettera dalla chain, si raccomanda di contrassegnarli come immutabili con `@entity(immutable: true)`. I mapping possono apportare modifiche alle entità immutabili, purché tali modifiche avvengano nello stesso blocco in cui l'entità è stata creata. Le entità immutabili sono molto più veloci da scrivere e da effettuare query e quindi dovrebbero essere utilizzate ogni volta che è possibile.

### Buon esempio

L'entità `Gravatar` qui sotto è strutturata intorno a un oggetto Gravatar ed è un buon esempio di come potrebbe essere definita un'entità.

```graphql
type Gravatar @entity(immutable: true) {
  id: Bytes!
  owner: Bytes
  displayName: String
  imageUrl: String
  accepted: Boolean
}
```

### Cattivo esempio

Gli esempi di entità `GravatarAccepted` e `GravatarDeclined` che seguono sono basati su eventi. Non è consigliabile mappare gli eventi o le chiamate di funzione alle entità 1:1.

```graphql
type GravatarAccepted @entity {
  id: Bytes!
  owner: Bytes
  displayName: String
  imageUrl: String
}

type GravatarDeclined @entity {
  id: Bytes!
  owner: Bytes
  displayName: String
  imageUrl: String
}
```

### Campi opzionali e obbligatori

I campi delle entità possono essere definiti come obbligatori o opzionali. I campi obbligatori sono indicati da `!` nello schema. Se un campo obbligatorio non è impostato nella mappatura, si riceverà questo errore quando si interroga il campo:

```
Null value resolved for non-null field 'name'
```

Ogni entità deve avere un campo `id`, che deve essere di tipo `Bytes!` oppure `String!`. In genere si raccomanda di usare `Bytes!`, a meno che il `id` non contenga testo leggibile dall'umano, poiché le entità con id `Bytes!` saranno più veloci da scrivere e da effettuare query rispetto a quelle con `String!` `id`. Il campo `id` serve come chiave primaria e deve essere unico per tutte le entità dello stesso tipo. Per ragioni storiche, è accettato anche il tipo `ID!`, sinonimo di `String!`.

Per alcuni tipi di entità, l'`id` è costruito a partire dagli id di altre due entità; ciò è possibile usando `concat`, ad esempio, `let id = left.id.concat(right.id)` per formare l'id dagli id di `left` e `right`. Allo stesso modo, per costruire un id a partire dall'id di un'entità esistente e da un contatore `count`, si può usare `let id = left.id.concatI32(count)`. La concatenazione è garantita per produrre id unici, purché la lunghezza di `left` sia la stessa per tutte queste entità, ad esempio perché `left.id` è un `Adress`.

### Tipi scalari integrati

#### Scalari supportati da GraphQL

Nella nostra API GraphQL supportiamo i seguenti scalari:

| Tipo         | Descrizione                                                                                                                                                                                                                                 |
| ------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `Bytes`      | Byte array, rappresentato come una stringa esadecimale. Comunemente utilizzato per gli hash e gli indirizzi di Ethereum.                                                                                                                    |
| `String`     | Scalare per valori `string`. I caratteri nulli non sono supportati e vengono rimossi automaticamente.                                                                                                                                       |
| `Boolean`    | Scalare per valori `boolean`.                                                                                                                                                                                                               |
| `Int`        | Le specifiche di GraphQL definiscono che `Int` ha una dimensione di 32 byte.                                                                                                                                                                |
| `Int8`       | Un intero firmato a 8 byte, noto anche come intero firmato a 64 bit, può memorizzare valori nell'intervallo da -9,223,372,036,854,775,808 a 9,223,372,036,854,775,807. È preferibile utilizzare questo per rappresentare `i64` da ethereum. |
| `BigInt`     | Numeri interi grandi. Utilizzati per i tipi `uint32`, `int64`, `uint64`, ..., `uint256` di Ethereum. Nota: Tutto ciò che è inferiore a `uint32` come `int32`, `uint24` oppure `int8` è rappresentato come `i32`.                            |
| `BigDecimal` | `BigDecimal` Decimali ad alta precisione rappresentati come un significante e un esponente. L'intervallo degli esponenti va da -6143 a +6144. Arrotondato a 34 cifre significative.                                                         |

#### Enum

È possibile creare enum anche all'interno di uno schema. Gli enum hanno la seguente sintassi:

```graphql
enum TokenStatus {
  OriginalOwner
  SecondOwner
  ThirdOwner
}
```

Una volta che l'enum è definito nello schema, si può usare la rappresentazione in stringa del valore dell'enum per impostare un campo enum su un'entità. Ad esempio, si può impostare il `tokenStatus` su `SecondOwner` definendo prima l'entità e poi impostando il campo con `entity.tokenStatus = "SecondOwner"`. L'esempio seguente mostra l'aspetto dell'entità Token con un campo enum:

Maggiori dettagli sulla scrittura degli enum si trovano nella [documentazione di GraphQL](https://graphql.org/learn/schema/).

#### Relazioni tra entità

Un'entità può avere una relazione con una o più altre entità dello schema. Queste relazioni possono essere attraversate nelle query. Le relazioni in The Graph sono unidirezionali. È possibile simulare relazioni bidirezionali definendo una relazione unidirezionale su entrambe le "estremità" della relazione.

Le relazioni sono definite sulle entità come qualsiasi altro campo, tranne per il fatto che il tipo specificato è quello di un'altra entità.

#### Rapporti uno-a-uno

Definire un tipo di entità `Transaction` con una relazione opzionale uno-a-uno con un tipo di entità `TransactionReceipt`:

```graphql
type Transaction @entity(immutable: true) {
  id: Bytes!
  transactionReceipt: TransactionReceipt
}

type TransactionReceipt @entity(immutable: true) {
  id: Bytes!
  transaction: Transaction
}
```

#### Relazioni uno-a-molti

Definire un tipo di entità `TokenBalance` con una relazione obbligatoria uno-a-molti con un tipo di entità Token:

```graphql
type Token @entity(immutable: true) {
  id: Bytes!
}

type TokenBalance @entity {
  id: Bytes!
  amount: Int!
  token: Token!
}
```

#### Ricerche inverse

Le ricerche inverse possono essere definite su un'entità attraverso il campo `@derivedFrom`. Questo crea un campo virtuale sull'entità che può essere interrogato, ma non può essere impostato manualmente attraverso l'API dei mapping. Piuttosto, è derivato dalla relazione definita sull'altra entità. Per tali relazioni, raramente ha senso memorizzare entrambi i lati della relazione e sia l'indicizzazione che le prestazioni delle query saranno migliori quando solo un lato è memorizzato e l'altro è derivato.

Per le relazioni uno-a-molti, la relazione deve sempre essere memorizzata sul lato "uno" e il lato "molti" deve sempre essere derivato. Memorizzare la relazione in questo modo, piuttosto che memorizzare un array di entità sul lato "molti", migliorerà notevolmente le prestazioni sia per l'indicizzazione che per l'interrogazione del subgraph. In generale, la memorizzazione di array di entità dovrebbe essere evitata per quanto possibile.

#### Esempio

Possiamo rendere accessibili i saldi di un token dal token stesso, derivando un campo `tokenBalances`:

```graphql
type Token @entity(immutable: true) {
  id: Bytes!
  tokenBalances: [TokenBalance!]! @derivedFrom(field: "token")
}

type TokenBalance @entity {
  id: Bytes!
  amount: Int!
  token: Token!
}
```

#### Relazioni molti-a-molti

Per le relazioni molti-a-molti, come ad esempio gli utenti che possono appartenere a un numero qualsiasi di organizzazioni, il modo più semplice, ma generalmente non il più performante, di modellare la relazione è come un array in ciascuna delle due entità coinvolte. Se la relazione è simmetrica, è necessario memorizzare solo un lato della relazione e l'altro lato può essere derivato.

#### Esempio

Definire una ricerca inversa da un tipo di entità `User` a un tipo di entità `Organization`. Nell'esempio seguente, questo si ottiene cercando l'attributo `members` dall'entità `Organization`. Nelle query, il campo `organizations` su `User` verrà risolto trovando tutte le entità `Organization` che includono l'ID dell'utente.

```graphql
type Organization @entity {
  id: Bytes!
  name: String!
  members: [User!]!
}

type User @entity {
  id: Bytes!
  name: String!
  organizations: [Organization!]! @derivedFrom(field: "members")
}
```

Un modo più performante per memorizzare questa relazione è una tabella di mappatura che ha una voce per ogni coppia `User` / `Organization` con uno schema come

```graphql
type Organization @entity {
  id: Bytes!
  name: String!
  members: [UserOrganization!]! @derivedFrom(field: "organization")
}

type User @entity {
  id: Bytes!
  name: String!
  organizations: [UserOrganization!] @derivedFrom(field: "user")
}

type UserOrganization @entity {
  id: Bytes! # Set to `user.id.concat(organization.id)`
  user: User!
  organization: Organization!
}
```

Questo approccio richiede che le query scendano di un ulteriore livello per recuperare, ad esempio, le organizzazioni degli utenti:

```graphql
query usersWithOrganizations {
  users {
    organizations {
      # this is a UserOrganization entity
      organization {
        name
      }
    }
  }
}
```

Questo modo più elaborato di memorizzare le relazioni molti-a-molti si traduce in una minore quantità di dati memorizzati per il subgraph e quindi in un subgraph che spesso è molto più veloce da indicizzare e da effettuare query.

#### Aggiungere commenti allo schema

Secondo le specifiche GraphQL, i commenti possono essere aggiunti sopra gli attributi delle entità dello schema usando le doppie virgolette `""`. Questo è illustrato nell'esempio seguente:

```graphql
type MyFirstEntity @entity {
  "unique identifier and primary key of the entity"
  id: Bytes!
  address: Bytes!
}
```

## Definizione dei campi di ricerca fulltext

Le query di ricerca fulltext filtrano e classificano le entità in base a un input di ricerca testuale. Le query full-text sono in grado di restituire corrispondenze per parole simili, elaborando il testo della query in gambi prima di confrontarli con i dati di testo indicizzati.

La definizione di una query fulltext include il nome della query, il dizionario linguistico utilizzato per elaborare i campi di testo, l'algoritmo di classificazione utilizzato per ordinare i risultati e i campi inclusi nella ricerca. Ogni query fulltext può comprendere più campi, ma tutti i campi inclusi devono appartenere a un unico tipo di entità.

Per aggiungere una query fulltext, includere un tipo `_Schema_` con una direttiva fulltext nello schema GraphQL.

```graphql
type _Schema_
  @fulltext(
    name: "bandSearch"
    language: en
    algorithm: rank
    include: [{ entity: "Band", fields: [{ name: "name" }, { name: "description" }, { name: "bio" }] }]
  )

type Band @entity {
  id: Bytes!
  name: String!
  description: String!
  bio: String
  wallet: Address
  labels: [Label!]!
  discography: [Album!]!
  members: [Musician!]!
}
```

Il campo di esempio `bandSearch` può essere utilizzato nelle query per filtrare le entità `Band` in base ai documenti di testo nei campi `name`, `description`, e `bio`. Passare a [GraphQL API - Queries](/querying/graphql-api#queries) per una descrizione dell'API di ricerca fulltext e per altri esempi di utilizzo.

```graphql
query {
  bandSearch(text: "breaks & electro & detroit") {
    id
    name
    description
    wallet
  }
}
```

> **[Feature Management](#experimental-features): **A partire dalla `specVersion` `0.0.4`, `fullTextSearch` deve essere dichiarato nella sezione `features` del manifesto del subgraph.

### Lingue supportate

La scelta di una lingua diversa avrà un effetto definitivo, anche se talvolta sottile, sull'API di ricerca fulltext. I campi coperti da una query fulltext vengono esaminati nel contesto della lingua scelta, quindi i lessemi prodotti dall'analisi e dalle query di ricerca variano da lingua a lingua. Ad esempio, quando si utilizza il dizionario turco supportato, "token" viene ridotto a "toke", mentre il dizionario inglese lo riduce a "token".

Dizionari linguistici supportati:

| Codice   | Dizionario |
| -------- | ---------- |
| semplice | Generale   |
| da       | Danese     |
| nl       | Olandese   |
| en       | Inglese    |
| fi       | Finlandese |
| fr       | Francese   |
| de       | Tedesco    |
| hu       | Ungherese  |
| it       | Italiano   |
| no       | Norvegese  |
| pt       | Portoghese |
| ro       | Rumeno     |
| ru       | Russo      |
| es       | Spagnolo   |
| sv       | Svedese    |
| tr       | Turco      |

### Algoritmi di classificazione

Algoritmi supportati per ordinare i risultati:

| Algoritmo     | Descrizione                                                                                   |
| ------------- | --------------------------------------------------------------------------------------------- |
| rank          | Utilizza la qualità della corrispondenza (0-1) della query fulltext per ordinare i risultati. |
| proximityRank | Simile a rank, ma include anche la vicinanza degli incontri.                                  |

## Scrivere le mappature

Le mappature prendono i dati da una particolare fonte e li trasformano in entità definite nello schema. Le mappature sono scritte in un sottoinsieme di [TypeScript](https://www.typescriptlang.org/docs/handbook/typescript-in-5-minutes.html) chiamato [AssemblyScript](https://github.com/AssemblyScript/assemblyscript/wiki) che può essere compilato in WASM ([WebAssembly](https://webassembly.org/)). AssemblyScript è più rigoroso del normale TypeScript, ma offre una sintassi familiare.

Per ogni gestore di eventi definito in `subgraph.yaml` sotto `mapping.eventHandlers`, creare una funzione esportata con lo stesso nome. Ogni gestore deve accettare un singolo parametro, chiamato `event`, con un tipo corrispondente al nome dell'evento da gestire.

Nel sottografo di esempio, `src/mapping.ts` contiene gestori per gli eventi `NewGravatar` e `UpdatedGravatar`:

```javascript
import { NewGravatar, UpdatedGravatar } from '../generated/Gravity/Gravity'
import { Gravatar } from '../generated/schema'

export function handleNewGravatar(event: NewGravatar): void {
  let gravatar = new Gravatar(event.params.id)
  gravatar.owner = event.params.owner
  gravatar.displayName = event.params.displayName
  gravatar.imageUrl = event.params.imageUrl
  gravatar.save()
}

export function handleUpdatedGravatar(event: UpdatedGravatar): void {
  let id = event.params.id
  let gravatar = Gravatar.load(id)
  if (gravatar == null) {
    gravatar = new Gravatar(id)
  }
  gravatar.owner = event.params.owner
  gravatar.displayName = event.params.displayName
  gravatar.imageUrl = event.params.imageUrl
  gravatar.save()
}
```

Il primo gestore prende un evento `NewGravatar` e crea una nuova entità `Gravatar` con `new Gravatar(event.params.id.toHex())`, popolando i campi dell'entità usando i parametri corrispondenti dell'evento. Questa istanza di entità è rappresentata dalla variabile `gravatar`, con un valore id di `event.params.id.toHex()`.

Il secondo gestore cerca di caricare il `Gravatar` esistente dal negozio dei Graph Node.Se non esiste ancora, viene creato su richiesta. L'entità viene quindi aggiornata in base ai nuovi parametri dell'evento, prima di essere salvata nel negozio con `gravatar.save()`.

### ID consigliati per la creazione di nuove entità

Ogni entità deve avere un `id` che sia unico tra tutte le entità dello stesso tipo. Il valore `id` di un'entità viene impostato quando l'entità viene creata. Di seguito sono riportati alcuni valori `id` consigliati da considerare quando si creano nuove entità. NOTA: Il valore di `id` deve essere una `string`.

- `event.params.id.toHex()`
- `event.transaction.from.toHex()`
- `event.transaction.hash.toHex() + "-" + event.logIndex.toString()`

Forniamo la [libreria Graph Typescript](https://github.com/graphprotocol/graph-ts) che contiene utili per interagire con il negozio Graph Node e comodità per gestire i dati e le entità degli smart contract. È possibile utilizzare questa libreria nelle mappature importando `@graphprotocol/graph-ts` in `mapping.ts`.

## Generazione del codice

Per rendere semplice e sicuro il lavoro con gli smart contract, gli eventi e le entità, la Graph CLI può generare tipi AssemblyScript dallo schema GraphQL del subgraph e dagli ABI dei contratti inclusi nelle data source.

Questo viene fatto con

```sh
graph codegen [--output-dir <OUTPUT_DIR>] [<MANIFEST>]
```

ma nella maggior parte dei casi, i subgraph sono già preconfigurati tramite `package.json` per consentire di eseguire semplicemente uno dei seguenti comandi per ottenere lo stesso risultato:

```sh
# Yarn
yarn codegen

# NPM
npm run codegen
```

Questo genera una classe AssemblyScript per ogni smart contract nei file ABI menzionati in `subgraph.yaml`, consentendo di legare questi contratti a indirizzi specifici nelle mappature e di chiamare i metodi del contratto in sola lettura contro il blocco in elaborazione. Verrà inoltre generata una classe per ogni evento contrattuale, per fornire un facile accesso ai parametri dell'evento, nonché al blocco e alla transazione da cui l'evento ha avuto origine. Tutti questi tipi sono scritti in `<OUTPUT_DIR>/<DATA_SOURCE_NAME>/<ABI_NAME>.ts`. Nel subgraph di esempio, questo sarebbe `generated/Gravity/Gravity.ts`, consentendo ai mapping di importare questi tipi con.

```javascript
import {
  // The contract class:
  Gravity,
  // The events classes:
  NewGravatar,
  UpdatedGravatar,
} from '../generated/Gravity/Gravity'
```

Inoltre, viene generata una classe per ogni tipo di entità nello schema GraphQL del subgraph. Queste classi forniscono il caricamento sicuro del tipo di entità, l'accesso in lettura e scrittura ai campi dell'entità e un metodo `save()` per scrivere le entità nella memoria. Tutte le classi di entità sono scritte in `<OUTPUT_DIR>/schema.ts`, consentendo alle mappature di importarle con

```javascript
import { Gravatar } from '../generated/schema'
```

> **Nota:** La generazione del codice deve essere eseguita nuovamente dopo ogni modifica allo schema GraphQL o alle ABI incluse nel manifesto. Inoltre, deve essere eseguita almeno una volta prima di costruire o distribuire il subgraph.

La generazione del codice non controlla il codice di mappatura in `src/mapping.ts`. Se si vuole controllare prima di provare a distribuire il subgraph in Graph Explorer, si può eseguire `yarn build` e correggere eventuali errori di sintassi che il compilatore TypeScript potrebbe trovare.

## Modelli di Data Source

Un modello comune negli smart contract compatibili con EVM è l'uso di contratti di registro o di fabbrica, in cui un contratto crea, gestisce o fa riferimento a un numero arbitrario di altri contratti che hanno ciascuno il proprio stato e i propri eventi.

Gli indirizzi di questi subcontratti possono o meno essere noti in anticipo e molti di questi contratti possono essere creati e/o aggiunti nel tempo. Per questo motivo, in questi casi, la definizione di una singola data source o di un numero fisso di data source è impossibile e occorre un approccio più dinamico: i _modelli di data source_.

### Data Source per il contratto principale

Per prima cosa, si definisce un data source regolare per il contratto principale. Lo snippet seguente mostra un esempio semplificato di data source per il contratto [Uniswap](https://uniswap.org) exchange factory. Si noti il gestore di eventi `NewExchange(address,address)`. Questo viene emesso quando un nuovo contratto di scambio viene creato sulla chain dal contratto di fabbrica.

```yaml
dataSources:
  - kind: ethereum/contract
    name: Factory
    network: mainnet
    source:
      address: '0xc0a47dFe034B400B47bDaD5FecDa2621de6c4d95'
      abi: Factory
    mapping:
      kind: ethereum/events
      apiVersion: 0.0.6
      language: wasm/assemblyscript
      file: ./src/mappings/factory.ts
      entities:
        - Directory
      abis:
        - name: Factory
          file: ./abis/factory.json
      eventHandlers:
        - event: NewExchange(address,address)
          handler: handleNewExchange
```

### Modelli di data source per contratti creati dinamicamente

Quindi, si aggiungono _modelli di data source_ al manifesto. Questi sono identici alle normali data source, tranne per il fatto che non hanno un indirizzo di contratto predefinito sotto `la fonte`. In genere, si definisce un modello per ogni tipo di subcontratto gestito o referenziato dal contratto principale.

```yaml
dataSources:
  - kind: ethereum/contract
    name: Factory
    # ... other source fields for the main contract ...
templates:
  - name: Exchange
    kind: ethereum/contract
    network: mainnet
    source:
      abi: Exchange
    mapping:
      kind: ethereum/events
      apiVersion: 0.0.6
      language: wasm/assemblyscript
      file: ./src/mappings/exchange.ts
      entities:
        - Exchange
      abis:
        - name: Exchange
          file: ./abis/exchange.json
      eventHandlers:
        - event: TokenPurchase(address,uint256,uint256)
          handler: handleTokenPurchase
        - event: EthPurchase(address,uint256,uint256)
          handler: handleEthPurchase
        - event: AddLiquidity(address,uint256,uint256)
          handler: handleAddLiquidity
        - event: RemoveLiquidity(address,uint256,uint256)
          handler: handleRemoveLiquidity
```

### Instantiating a Data Source Template

In the final step, you update your main contract mapping to create a dynamic data source instance from one of the templates. In this example, you would change the main contract mapping to import the `Exchange` template and call the `Exchange.create(address)` method on it to start indexing the new exchange contract.

```typescript
import { Exchange } from '../generated/templates'

export function handleNewExchange(event: NewExchange): void {
  // Start indexing the exchange; `event.params.exchange` is the
  // address of the new exchange contract
  Exchange.create(event.params.exchange)
}
```

> **Note:** A new data source will only process the calls and events for the block in which it was created and all following blocks, but will not process historical data, i.e., data that is contained in prior blocks.
> 
> If prior blocks contain data relevant to the new data source, it is best to index that data by reading the current state of the contract and creating entities representing that state at the time the new data source is created.

### Data Source Context

Data source contexts allow passing extra configuration when instantiating a template. In our example, let's say exchanges are associated with a particular trading pair, which is included in the `NewExchange` event. That information can be passed into the instantiated data source, like so:

```typescript
import { Exchange } from '../generated/templates'

export function handleNewExchange(event: NewExchange): void {
  let context = new DataSourceContext()
  context.setString('tradingPair', event.params.tradingPair)
  Exchange.createWithContext(event.params.exchange, context)
}
```

Inside a mapping of the `Exchange` template, the context can then be accessed:

```typescript
import { dataSource } from '@graphprotocol/graph-ts'

let context = dataSource.context()
let tradingPair = context.getString('tradingPair')
```

There are setters and getters like `setString` and `getString` for all value types.

## Start Blocks

The `startBlock` is an optional setting that allows you to define from which block in the chain the data source will start indexing. Setting the start block allows the data source to skip potentially millions of blocks that are irrelevant. Typically, a subgraph developer will set `startBlock` to the block in which the smart contract of the data source was created.

```yaml
dataSources:
  - kind: ethereum/contract
    name: ExampleSource
    network: mainnet
    source:
      address: '0xc0a47dFe034B400B47bDaD5FecDa2621de6c4d95'
      abi: ExampleContract
      startBlock: 6627917
    mapping:
      kind: ethereum/events
      apiVersion: 0.0.6
      language: wasm/assemblyscript
      file: ./src/mappings/factory.ts
      entities:
        - User
      abis:
        - name: ExampleContract
          file: ./abis/ExampleContract.json
      eventHandlers:
        - event: NewEvent(address,address)
          handler: handleNewEvent
```

> **Note:** The contract creation block can be quickly looked up on Etherscan:
> 
> 1. Search for the contract by entering its address in the search bar.
> 2. Click on the creation transaction hash in the `Contract Creator` section.
> 3. Load the transaction details page where you'll find the start block for that contract.

## Call Handlers

While events provide an effective way to collect relevant changes to the state of a contract, many contracts avoid generating logs to optimize gas costs. In these cases, a subgraph can subscribe to calls made to the data source contract. This is achieved by defining call handlers referencing the function signature and the mapping handler that will process calls to this function. To process these calls, the mapping handler will receive an `ethereum.Call` as an argument with the typed inputs to and outputs from the call. Calls made at any depth in a transaction's call chain will trigger the mapping, allowing activity with the data source contract through proxy contracts to be captured.

Call handlers will only trigger in one of two cases: when the function specified is called by an account other than the contract itself or when it is marked as external in Solidity and called as part of another function in the same contract.

> **Note:** Call handlers currently depend on the Parity tracing API. Certain networks, such as BNB chain and Arbitrum, does not support this API. If a subgraph indexing one of these networks contain one or more call handlers, it will not start syncing. Subgraph developers should instead use event handlers. These are far more performant than call handlers, and are supported on every evm network.

### Defining a Call Handler

To define a call handler in your manifest, simply add a `callHandlers` array under the data source you would like to subscribe to.

```yaml
dataSources:
  - kind: ethereum/contract
    name: Factory
    network: mainnet
    source:
      address: '0xc0a47dFe034B400B47bDaD5FecDa2621de6c4d95'
      abi: Factory
    mapping:
      kind: ethereum/events
      apiVersion: 0.0.6
      language: wasm/assemblyscript
      file: ./src/mappings/factory.ts
      entities:
        - Directory
      abis:
        - name: Factory
          file: ./abis/factory.json
      eventHandlers:
        - event: NewExchange(address,address)
          handler: handleNewExchange
```

The `function` is the normalized function signature to filter calls by. The `handler` property is the name of the function in your mapping you would like to execute when the target function is called in the data source contract.

### Mapping Function

Each call handler takes a single parameter that has a type corresponding to the name of the called function. In the example subgraph above, the mapping contains a handler for when the `createGravatar` function is called and receives a `CreateGravatarCall` parameter as an argument:

```typescript
import { CreateGravatarCall } from '../generated/Gravity/Gravity'
import { Transaction } from '../generated/schema'

export function handleCreateGravatar(call: CreateGravatarCall): void {
  let id = call.transaction.hash
  let transaction = new Transaction(id)
  transaction.displayName = call.inputs._displayName
  transaction.imageUrl = call.inputs._imageUrl
  transaction.save()
}
```

The `handleCreateGravatar` function takes a new `CreateGravatarCall` which is a subclass of `ethereum.Call`, provided by `@graphprotocol/graph-ts`, that includes the typed inputs and outputs of the call. The `CreateGravatarCall` type is generated for you when you run `graph codegen`.

## Block Handlers

In addition to subscribing to contract events or function calls, a subgraph may want to update its data as new blocks are appended to the chain. To achieve this a subgraph can run a function after every block or after blocks that match a pre-defined filter.

### Supported Filters

#### Call Filter

```yaml
filter:
  kind: call
```

_The defined handler will be called once for every block which contains a call to the contract (data source) the handler is defined under._

> **Note:** The `call` filter currently depend on the Parity tracing API. Certain networks, such as BNB chain and Arbitrum, does not support this API. If a subgraph indexing one of these networks contain one or more block handlers with a `call` filter, it will not start syncing.

The absence of a filter for a block handler will ensure that the handler is called every block. A data source can only contain one block handler for each filter type.

```yaml
dataSources:
  - kind: ethereum/contract
    name: Gravity
    network: dev
    source:
      address: '0x731a10897d267e19b34503ad902d0a29173ba4b1'
      abi: Gravity
    mapping:
      kind: ethereum/events
      apiVersion: 0.0.6
      language: wasm/assemblyscript
      entities:
        - Gravatar
        - Transaction
      abis:
        - name: Gravity
          file: ./abis/Gravity.json
      blockHandlers:
        - handler: handleBlock
        - handler: handleBlockWithCallToContract
          filter:
            kind: call
```

#### Polling Filter

> **Requires `specVersion` >= 0.0.8**

> **Note:** Polling filters are only available on dataSources of `kind: ethereum`.

```yaml
blockHandlers:
  - handler: handleBlock
    filter:
      kind: polling
      every: 10
```

The defined handler will be called once for every `n` blocks, where `n` is the value provided in the `every` field. This configuration allows the subgraph to perform specific operations at regular block intervals.

#### Once Filter

> **Requires `specVersion` >= 0.0.8**

> **Note:** Once filters are only available on dataSources of `kind: ethereum`.

```yaml
blockHandlers:
  - handler: handleOnce
    filter:
      kind: once
```

The defined handler with the once filter will be called only once before all other handlers run. This configuration allows the subgraph to use the handler as an initialization handler, performing specific tasks at the start of indexing.

```ts
export function handleOnce(block: ethereum.Block): void {
  let data = new InitialData(Bytes.fromUTF8('initial'))
  data.data = 'Setup data here'
  data.save()
}
```

### Mapping Function

The mapping function will receive an `ethereum.Block` as its only argument. Like mapping functions for events, this function can access existing subgraph entities in the store, call smart contracts and create or update entities.

```typescript
import { ethereum } from '@graphprotocol/graph-ts'

export function handleBlock(block: ethereum.Block): void {
  let id = block.hash
  let entity = new Block(id)
  entity.save()
}
```

## Anonymous Events

If you need to process anonymous events in Solidity, that can be achieved by providing the topic 0 of the event, as in the example:

```yaml
eventHandlers:
  - event: LogNote(bytes4,address,bytes32,bytes32,uint256,bytes)
    topic0: '0x644843f351d3fba4abcd60109eaff9f54bac8fb8ccf0bab941009c21df21cf31'
    handler: handleGive
```

An event will only be triggered when both the signature and topic 0 match. By default, `topic0` is equal to the hash of the event signature.

## Transaction Receipts in Event Handlers

Starting from `specVersion` `0.0.5` and `apiVersion` `0.0.7`, event handlers can have access to the receipt for the transaction which emitted them.

To do so, event handlers must be declared in the subgraph manifest with the new `receipt: true` key, which is optional and defaults to false.

```yaml
eventHandlers:
  - event: NewGravatar(uint256,address,string,string)
    handler: handleNewGravatar
    receipt: true
```

Inside the handler function, the receipt can be accessed in the `Event.receipt` field. When the `receipt` key is set to `false` or omitted in the manifest, a `null` value will be returned instead.

## Experimental features

Starting from `specVersion` `0.0.4`, subgraph features must be explicitly declared in the `features` section at the top level of the manifest file, using their `camelCase` name, as listed in the table below:

| Feature                                                   | Name                                                |
| --------------------------------------------------------- | --------------------------------------------------- |
| [Non-fatal errors](#non-fatal-errors)                     | `nonFatalErrors`                                    |
| [Full-text Search](#defining-fulltext-search-fields)      | `fullTextSearch`                                    |
| [Grafting](#grafting-onto-existing-subgraphs)             | `grafting`                                          |
| [IPFS on Ethereum Contracts](#ipfs-on-ethereum-contracts) | `ipfsOnEthereumContracts` or `nonDeterministicIpfs` |

For instance, if a subgraph uses the **Full-Text Search** and the **Non-fatal Errors** features, the `features` field in the manifest should be:

```yaml
specVersion: 0.0.4
description: Gravatar for Ethereum
features:
  - fullTextSearch
  - nonFatalErrors
dataSources: ...
```

Note that using a feature without declaring it will incur a **validation error** during subgraph deployment, but no errors will occur if a feature is declared but not used.

### IPFS on Ethereum Contracts

A common use case for combining IPFS with Ethereum is to store data on IPFS that would be too expensive to maintain on-chain, and reference the IPFS hash in Ethereum contracts.

Given such IPFS hashes, subgraphs can read the corresponding files from IPFS using `ipfs.cat` and `ipfs.map`. To do this reliably, it is required that these files are pinned to an IPFS node with high availability, so that the [hosted service](https://thegraph.com/hosted-service) IPFS node can find them during indexing.

> **Note:** The Graph Network does not yet support `ipfs.cat` and `ipfs.map`, and developers should not deploy subgraphs using that functionality to the network via the Studio.

> **[Feature Management](#experimental-features):** `ipfsOnEthereumContracts` must be declared under `features` in the subgraph manifest. For non EVM chains, the `nonDeterministicIpfs` alias can also be used for the same purpose.

When running a local Graph Node, the `GRAPH_ALLOW_NON_DETERMINISTIC_IPFS` environment variable must be set in order to index subgraphs using this experimental functionality.

### Non-fatal errors

Indexing errors on already synced subgraphs will, by default, cause the subgraph to fail and stop syncing. Subgraphs can alternatively be configured to continue syncing in the presence of errors, by ignoring the changes made by the handler which provoked the error. This gives subgraph authors time to correct their subgraphs while queries continue to be served against the latest block, though the results might be inconsistent due to the bug that caused the error. Note that some errors are still always fatal. To be non-fatal, the error must be known to be deterministic.

> **Note:** The Graph Network does not yet support non-fatal errors, and developers should not deploy subgraphs using that functionality to the network via the Studio.

Enabling non-fatal errors requires setting the following feature flag on the subgraph manifest:

```yaml
specVersion: 0.0.4
description: Gravatar for Ethereum
features:
    - nonFatalErrors
    ...
```

The query must also opt-in to querying data with potential inconsistencies through the `subgraphError` argument. It is also recommended to query `_meta` to check if the subgraph has skipped over errors, as in the example:

```graphql
foos(first: 100, subgraphError: allow) {
  id
}

_meta {
  hasIndexingErrors
}
```

If the subgraph encounters an error, that query will return both the data and a graphql error with the message `"indexing_error"`, as in this example response:

```graphql
"data": {
    "foos": [
        {
          "id": "0xdead"
        }
    ],
    "_meta": {
        "hasIndexingErrors": true
    }
},
"errors": [
    {
        "message": "indexing_error"
    }
]
```

### Grafting onto Existing Subgraphs

> **Note:** it is not recommended to use grafting when initially upgrading to The Graph Network. Learn more [here](/cookbook/grafting/#important-note-on-grafting-when-upgrading-to-the-network).

When a subgraph is first deployed, it starts indexing events at the genesis block of the corresponding chain (or at the `startBlock` defined with each data source) In some circumstances; it is beneficial to reuse the data from an existing subgraph and start indexing at a much later block. This mode of indexing is called _Grafting_. Grafting is, for example, useful during development to get past simple errors in the mappings quickly or to temporarily get an existing subgraph working again after it has failed.

A subgraph is grafted onto a base subgraph when the subgraph manifest in `subgraph.yaml` contains a `graft` block at the top-level:

```yaml
description: ...
graft:
  base: Qm... # Subgraph ID of base subgraph
  block: 7345624 # Block number
```

When a subgraph whose manifest contains a `graft` block is deployed, Graph Node will copy the data of the `base` subgraph up to and including the given `block` and then continue indexing the new subgraph from that block on. The base subgraph must exist on the target Graph Node instance and must have indexed up to at least the given block. Because of this restriction, grafting should only be used during development or during an emergency to speed up producing an equivalent non-grafted subgraph.

Because grafting copies rather than indexes base data, it is much quicker to get the subgraph to the desired block than indexing from scratch, though the initial data copy can still take several hours for very large subgraphs. While the grafted subgraph is being initialized, the Graph Node will log information about the entity types that have already been copied.

The grafted subgraph can use a GraphQL schema that is not identical to the one of the base subgraph, but merely compatible with it. It has to be a valid subgraph schema in its own right, but may deviate from the base subgraph's schema in the following ways:

- It adds or removes entity types
- It removes attributes from entity types
- It adds nullable attributes to entity types
- It turns non-nullable attributes into nullable attributes
- It adds values to enums
- It adds or removes interfaces
- It changes for which entity types an interface is implemented

> **[Feature Management](#experimental-features):** `grafting` must be declared under `features` in the subgraph manifest.

## File Data Sources

File data sources are a new subgraph functionality for accessing off-chain data during indexing in a robust, extendable way. File data sources support fetching files from IPFS and from Arweave.

> This also lays the groundwork for deterministic indexing of off-chain data, as well as the potential introduction of arbitrary HTTP-sourced data.

### Panoramica

Rather than fetching files "in line" during handler exectuion, this introduces templates which can be spawned as new data sources for a given file identifier. These new data sources fetch the files, retrying if they are unsuccessful, running a dedicated handler when the file is found.

This is similar to the [existing data source templates](https://thegraph.com/docs/en/developing/creating-a-subgraph/#data-source-templates), which are used to dynamically create new chain-based data sources.

> This replaces the existing `ipfs.cat` API

### Upgrade guide

#### Update `graph-ts` and `graph-cli`

File data sources requires graph-ts >=0.29.0 and graph-cli >=0.33.1

#### Add a new entity type which will be updated when files are found

File data sources cannot access or update chain-based entities, but must update file specific entities.

This may mean splitting out fields from existing entities into separate entities, linked together.

Original combined entity:

```graphql
type Token @entity {
  id: ID!
  tokenID: BigInt!
  tokenURI: String!
  externalURL: String!
  ipfsURI: String!
  image: String!
  name: String!
  description: String!
  type: String!
  updatedAtTimestamp: BigInt
  owner: User!
}
```

New, split entity:

```graphql
type Token @entity {
  id: ID!
  tokenID: BigInt!
  tokenURI: String!
  ipfsURI: TokenMetadata
  updatedAtTimestamp: BigInt
  owner: String!
}

type TokenMetadata @entity {
  id: ID!
  image: String!
  externalURL: String!
  name: String!
  description: String!
}
```

If the relationship is 1:1 between the parent entity and the resulting file data source entity, the simplest pattern is to link the parent entity to a resulting file entity by using the IPFS CID as the lookup. Get in touch on Discord if you are having difficulty modelling your new file-based entities!

> You can use [nested filters](https://thegraph.com/docs/en/querying/graphql-api/#example-for-nested-entity-filtering) to filter parent entities on the basis of these nested entities.

#### Add a new templated data source with `kind: file/ipfs` or `kind: file/arweave`

This is the data source which will be spawned when a file of interest is identified.

```yaml
templates:
  - name: TokenMetadata
    kind: file/ipfs
    mapping:
      apiVersion: 0.0.7
      language: wasm/assemblyscript
      file: ./src/mapping.ts
      handler: handleMetadata
      entities:
        - TokenMetadata
      abis:
        - name: Token
          file: ./abis/Token.json
```

> Currently `abis` are required, though it is not possible to call contracts from within file data sources

The file data source must specifically mention all the entity types which it will interact with under `entities`. See [limitations](#Limitations) for more details.

#### Create a new handler to process files

This handler should accept one `Bytes` parameter, which will be the contents of the file, when it is found, which can then be processed. This will often be a JSON file, which can be processed with `graph-ts` helpers ([documentation](https://thegraph.com/docs/en/developing/assemblyscript-api/#json-api)).

The CID of the file as a readable string can be accessed via the `dataSource` as follows:

```typescript
const cid = dataSource.stringParam()
```

Example handler:

```typescript
import { json, Bytes, dataSource } from '@graphprotocol/graph-ts'
import { TokenMetadata } from '../generated/schema'

export function handleMetadata(content: Bytes): void {
  let tokenMetadata = new TokenMetadata(dataSource.stringParam())
  const value = json.fromBytes(content).toObject()
  if (value) {
    const image = value.get('image')
    const name = value.get('name')
    const description = value.get('description')
    const externalURL = value.get('external_url')

    if (name && image && description && externalURL) {
      tokenMetadata.name = name.toString()
      tokenMetadata.image = image.toString()
      tokenMetadata.externalURL = externalURL.toString()
      tokenMetadata.description = description.toString()
    }

    tokenMetadata.save()
  }
}
```

#### Spawn file data sources when required

You can now create file data sources during execution of chain-based handlers:

- Import the template from the auto-generated `templates`
- call `TemplateName.create(cid: string)` from within a mapping, where the cid is a valid content identifier for IPFS or Arweave

For IPFS, Graph Node supports [v0 and v1 content identifiers](https://docs.ipfs.tech/concepts/content-addressing/), and content identifers with directories (e.g. `bafyreighykzv2we26wfrbzkcdw37sbrby4upq7ae3aqobbq7i4er3tnxci/metadata.json`).

For Arweave, as of version 0.33.0 Graph Node can fetch files stored on Arweave based on their [transaction ID](https://docs.arweave.org/developers/server/http-api#transactions) from an Arweave gateway ([example file](https://bdxujjl5ev5eerd5ouhhs6o4kjrs4g6hqstzlci5pf6vhxezkgaa.arweave.net/CO9EpX0lekJEfXUOeXncUmMuG8eEp5WJHXl9U9yZUYA)). Arweave supports transactions uploaded via Bundlr, and Graph Node can also fetch files based on [Bundlr manifests](https://docs.bundlr.network/learn/gateways#indexing).

Example:

```typescript
import { TokenMetadata as TokenMetadataTemplate } from '../generated/templates'

const ipfshash = 'QmaXzZhcYnsisuue5WRdQDH6FDvqkLQX1NckLqBYeYYEfm'
//This example code is for a Crypto coven subgraph. The above ipfs hash is a directory with token metadata for all crypto coven NFTs.

export function handleTransfer(event: TransferEvent): void {
  let token = Token.load(event.params.tokenId.toString())
  if (!token) {
    token = new Token(event.params.tokenId.toString())
    token.tokenID = event.params.tokenId

    token.tokenURI = '/' + event.params.tokenId.toString() + '.json'
    const tokenIpfsHash = ipfshash + token.tokenURI
    //This creates a path to the metadata for a single Crypto coven NFT. It concats the directory with "/" + filename + ".json"

    token.ipfsURI = tokenIpfsHash

    TokenMetadataTemplate.create(tokenIpfsHash)
  }

  token.updatedAtTimestamp = event.block.timestamp
  token.owner = event.params.to.toHexString()
  token.save()
}
```

This will create a new file data source, which will poll Graph Node's configured IPFS or Arweave endpoint, retrying if it is not found. When the file is found, the file data source handler will be executed.

This example is using the CID as the lookup between the parent `Token` entity and the resulting `TokenMetadata` entity.

> Previously, this is the point at which a subgraph developer would have called `ipfs.cat(CID)` to fetch the file

Congratulations, you are using file data sources!

#### Deploying your subgraphs

You can now `build` and `deploy` your subgraph to any Graph Node >=v0.30.0-rc.0.

#### Limitations

File data source handlers and entities are isolated from other subgraph entities, ensuring that they are deterministic when executed, and ensuring no contamination of chain-based data sources. To be specific:

- Entities created by File Data Sources are immutable, and cannot be updated
- File Data Source handlers cannot access entities from other file data sources
- Entities associated with File Data Sources cannot be accessed by chain-based handlers

> While this constraint should not be problematic for most use-cases, it may introduce complexity for some. Please get in touch via Discord if you are having issues modelling your file-based data in a subgraph!

Additionally, it is not possible to create data sources from a file data source, be it an onchain data source or another file data source. This restriction may be lifted in the future.

#### Best practices

If you are linking NFT metadata to corresponding tokens, use the metadata's IPFS hash to reference a Metadata entity from the Token entity. Save the Metadata entity using the IPFS hash as an ID.

You can use [DataSource context](https://thegraph.com/docs/en/developing/assemblyscript-api/#entity-and-data-source-context) when creating File Data Sources to pass extra information which will be available to the File Data Source handler.

If you have entities which are refreshed multiple times, create unique file-based entities using the IPFS hash & the entity ID, and reference them using a derived field in the chain-based entity.

> We are working to improve the above recommendation, so queries only return the "most recent" version

#### Known issues

File data sources currently require ABIs, even though ABIs are not used ([issue](https://github.com/graphprotocol/graph-cli/issues/961)). Workaround is to add any ABI.

Handlers for File Data Sources cannot be in files which import `eth_call` contract bindings, failing with "unknown import: `ethereum::ethereum.call` has not been defined" ([issue](https://github.com/graphprotocol/graph-cli/issues/4309)). Workaround is to create file data source handlers in a dedicated file.

#### Esempi

[Crypto Coven Subgraph migration](https://github.com/azf20/cryptocoven-api/tree/file-data-sources-refactor)

#### References

[GIP File Data Sources](https://forum.thegraph.com/t/gip-file-data-sources/2721)
